{
 "metadata": {
  "name": "",
  "signature": "sha256:f950e8211df26671f8956a4a336f819b643594d4044d1b1a7e17fb56d1fcc335"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import theano\n",
      "import theano.tensor as T\n",
      "import numpy as np\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "example 1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define shared variables\n",
      "k = theano.shared(0)\n",
      "n_sym = T.iscalar(\"n_sym\")\n",
      "results,updates = theano.scan(lambda:{k:(k+2)},n_steps = n_sym)\n",
      "accumulator = theano.function([n_sym],[],updates = updates,allow_input_downcast=True)\n",
      "k.get_value()\n",
      "accumulator(50)\n",
      "k.get_value()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "example 2"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = T.matrix(\"X\")\n",
      "W = T.matrix(\"W\")\n",
      "b_sym = T.vector(\"b_sym\")\n",
      "# results,updates = theano.scan(lambda v:T.tanh(T.dot(v,W) + b_sym),sequences = X)\n",
      "results,updates = theano.scan(lambda v:T.dot(v,W) + b_sym,sequences = X)\n",
      "compute_elementwise = theano.function(inputs=[X,W,b_sym],outputs=[results])\n",
      "\n",
      "#test values\n",
      "x = np.eye(2,dtype = theano.config.floatX)\n",
      "w = np.ones((2,2),dtype = theano.config.floatX)\n",
      "b = np.ones((2),dtype = theano.config.floatX)\n",
      "b[1] = 2\n",
      "print x + b\n",
      "print compute_elementwise(x,w,b)[0]\n",
      "\n",
      "#comparison with numpy\n",
      "print x.dot(w) + b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 2.  2.]\n",
        " [ 1.  3.]]\n",
        "[[ 2.  3.]\n",
        " [ 2.  3.]]\n",
        "[[ 2.  3.]\n",
        " [ 2.  3.]]\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "example 3"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k = T.iscalar(\"k\")\n",
      "A = T.vector(\"A\")\n",
      "\n",
      "# Symbolic description of the result\n",
      "# outputs_info:the initial iterator parameter values,will be set with the output in the next iteration\n",
      "result, updates = theano.scan(fn=lambda prior_result, A: prior_result * A + A,\n",
      "outputs_info= T.ones_like(A),\n",
      "non_sequences=A,\n",
      "n_steps=k)\n",
      "\n",
      "# We only care about A**k, but scan has provided us with A**1 through A**k.\n",
      "# Discard the values that we don\u2018t care about. Scan is smart enough to\n",
      "# notice this and not waste memory saving them.\n",
      "final_result = result\n",
      "\n",
      "# compiled function that returns A**k\n",
      "power = theano.function(inputs=[A,k], outputs=final_result, updates=updates)\n",
      "\n",
      "res = power(range(10),2)\n",
      "\n",
      "print res.shape\n",
      "print res\n",
      "# print power(range(10),4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "<lambda>() takes exactly 2 arguments (1 given)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-30-24e306e6fc20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m result, updates = theano.scan(fn=lambda prior_result, A: prior_result * A + A,\n\u001b[1;32m      7\u001b[0m \u001b[0moutputs_info\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m n_steps=k)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# We only care about A**k, but scan has provided us with A**1 through A**k.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/scan_module/scan.pyc\u001b[0m in \u001b[0;36mscan\u001b[0;34m(fn, sequences, outputs_info, non_sequences, n_steps, truncate_gradient, go_backwards, mode, name, profile, allow_gc, strict)\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;31m# and outputs that needs to be separated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m     \u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscan_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_updates_and_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcondition\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0mas_while\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: <lambda>() takes exactly 2 arguments (1 given)"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "example 3 plus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k = T.iscalar(\"k\")\n",
      "A = T.matrix(\"A\")\n",
      "\n",
      "# Symbolic description of the result\n",
      "# outputs_info:the initial iterator parameter values \n",
      "result, updates = theano.scan(fn=lambda A,prior_result: prior_result*A,sequences=A, \n",
      "outputs_info= T.ones_like(A[-1]),\n",
      "n_steps=k)\n",
      "\n",
      "\n",
      "# We only care about A**k, but scan has provided us with A**1 through A**k.\n",
      "# Discard the values that we don\u2018t care about. Scan is smart enough to\n",
      "# notice this and not waste memory saving them.\n",
      "final_result = result\n",
      "\n",
      "# compiled function that returns A**k\n",
      "power = theano.function(inputs=[A,k], outputs=final_result, updates=updates)\n",
      "\n",
      "res = power([[2,3],[4,5]],2)\n",
      "\n",
      "print res.shape\n",
      "print res\n",
      "# print power(range(10),4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(2, 2)\n",
        "[[  2.   3.]\n",
        " [  8.  15.]]\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "example 4"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = T.matrix(\"X\")\n",
      "W = T.matrix(\"W\")\n",
      "b_sym = T.vector(\"b_sym\")\n",
      "\n",
      "results, updates = theano.scan(lambda v: T.dot(v, W) + b_sym, sequences=X)\n",
      "compute_elementwise = theano.function(inputs=[X, W, b_sym], outputs=[results])\n",
      "\n",
      "# test values\n",
      "x = np.eye(2, dtype=theano.config.floatX)\n",
      "w = np.ones((2, 2), dtype=theano.config.floatX)\n",
      "b = np.ones((2), dtype=theano.config.floatX)\n",
      "b[1] = 2\n",
      "print compute_elementwise(x, w, b)\n",
      "# comparison with numpy\n",
      "# print np.tanh(x.dot(w) + b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[array([[ 2.,  3.],\n",
        "       [ 2.,  3.]], dtype=float32)]\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "example 5:test ones_likes, means to generate a matrix whoes shape is the same as x"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import theano\n",
      "import theano.tensor as T\n",
      "import numpy as np\n",
      "\n",
      "x = T.lmatrix()\n",
      "cost = T.ones_like(x) #\n",
      "\n",
      "test_fn = theano.function(inputs = [x],outputs = [cost])\n",
      "res = test_fn([[2,3]])\n",
      "print(res)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[array([[1, 1]])]\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "example 5:categorical_crossentropy:  O(i) = -log(X(y(i)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf-8 -*-\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "import numpy as np\n",
      "from sklearn import datasets\n",
      "import matplotlib.pyplot as plt\n",
      "import time\n",
      "\n",
      "train_x = np.array([[0.1,2,3],[0.8,1,4],[16,3,90]])\n",
      "train_y = np.array([0,1,0])\n",
      "train_x = train_x.astype(np.float32)\n",
      "train_y = train_y.astype(np.int64)\n",
      "# train_x = np.ones((2,3),dtype=np.float32)\n",
      "# train_y = np.zeros((2),dtype=np.int64)\n",
      "\n",
      "#\u8bbe\u7f6e\u5171\u4eab\u53d8\u91cf\n",
      "nn_input_dim = 3\n",
      "nn_hdim = 2\n",
      "w1=theano.shared(np.random.randn(nn_input_dim,nn_hdim),name=\"W1\")\n",
      "b1=theano.shared(np.zeros(nn_hdim),name=\"b1\")\n",
      "\n",
      "\n",
      "#\u524d\u9988\u7b97\u6cd5\n",
      "X=T.matrix('X')  #double\u7c7b\u578b\u7684\u77e9\u9635\n",
      "y=T.lvector('y') #int64\u7c7b\u578b\u7684\u5411\u91cf\n",
      "loss=T.nnet.categorical_crossentropy(X,y)\n",
      "means=T.nnet.categorical_crossentropy(X,y).mean()\n",
      "\n",
      "calculate_loss=theano.function([X,y],loss)\n",
      "\n",
      "l = calculate_loss(train_x,train_y)\n",
      "print l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 2.30258512 -0.         -2.77258873]\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "example 7:theano training"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf-8 -*-\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "import numpy as np\n",
      "from sklearn import datasets\n",
      "import matplotlib.pyplot as plt\n",
      "import time\n",
      "#\u5b9a\u4e49\u6570\u636e\u7c7b\u578b\n",
      "\n",
      "np.random.seed(0)\n",
      "train_X, train_y = datasets.make_moons(300, noise=0.20)\n",
      "train_X = train_X.astype(np.float32)\n",
      "train_y = train_y.astype(np.int32)\n",
      "num_example=len(train_X)\n",
      "\n",
      "#\u8bbe\u7f6e\u53c2\u6570\n",
      "nn_input_dim=2 #\u8f93\u5165\u795e\u7ecf\u5143\u4e2a\u6570\n",
      "nn_output_dim=2 #\u8f93\u51fa\u795e\u7ecf\u5143\u4e2a\u6570\n",
      "nn_hdim=100\n",
      "#\u68af\u5ea6\u4e0b\u964d\u53c2\u6570\n",
      "epsilon=0.01 #learning rate\n",
      "reg_lambda=0.01 #\u6b63\u5219\u5316\u957f\u5ea6\n",
      "\n",
      "\n",
      "#\u8bbe\u7f6e\u5171\u4eab\u53d8\u91cf\n",
      "\n",
      "w1=theano.shared(np.random.randn(nn_input_dim,nn_hdim),name=\"W1\")\n",
      "b1=theano.shared(np.zeros(nn_hdim),name=\"b1\")\n",
      "w2=theano.shared(np.random.randn(nn_hdim,nn_output_dim),name=\"W2\")\n",
      "b2=theano.shared(np.zeros(nn_output_dim),name=\"b2\")\n",
      "\n",
      "#\u524d\u9988\u7b97\u6cd5\n",
      "X=T.matrix('X')  #double\u7c7b\u578b\u7684\u77e9\u9635\n",
      "y=T.lvector('y') #int64\u7c7b\u578b\u7684\u5411\u91cf\n",
      "z1=X.dot(w1)+b1\n",
      "a1=T.tanh(z1)\n",
      "z2=a1.dot(w2)+b2\n",
      "y_hat=T.nnet.softmax(z2)\n",
      "#\u6b63\u5219\u5316\u9879\n",
      "loss_reg=1./num_example * reg_lambda/2 * (T.sum(T.square(w1))+T.sum(T.square(w2)))\n",
      "loss=T.nnet.categorical_crossentropy(y_hat,y).mean()+loss_reg\n",
      "#\u9884\u6d4b\u7ed3\u679c\n",
      "prediction=T.argmax(y_hat,axis=1)\n",
      "\n",
      "forword_prop=theano.function([X],y_hat)\n",
      "calculate_loss=theano.function([X,y],loss)\n",
      "predict=theano.function([X],prediction)\n",
      "\n",
      "\n",
      "#\u6c42\u5bfc\n",
      "dw2=T.grad(loss,w2)\n",
      "db2=T.grad(loss,b2)\n",
      "dw1=T.grad(loss,w1)\n",
      "db1=T.grad(loss,b1)\n",
      "\n",
      "#\u66f4\u65b0\u503c\n",
      "gradient_step=theano.function(\n",
      "    [X,y],\n",
      "    updates=(\n",
      "        (w2,w2-epsilon*dw2),\n",
      "        (b2,b2-epsilon*db2),\n",
      "        (w1,w1-epsilon*dw1),\n",
      "        (b1,b1-epsilon*db1)\n",
      "\n",
      "    )\n",
      ")\n",
      "\n",
      "def build_model(num_passes=20000,print_loss=False):\n",
      "\n",
      "    w1.set_value(np.random.randn(nn_input_dim, nn_hdim) / np.sqrt(nn_input_dim))\n",
      "    b1.set_value(np.zeros(nn_hdim))\n",
      "    w2.set_value(np.random.randn(nn_hdim, nn_output_dim) / np.sqrt(nn_hdim))\n",
      "    b2.set_value(np.zeros(nn_output_dim))\n",
      "\n",
      "    for i in xrange(0,num_passes):\n",
      "        gradient_step(train_X,train_y)\n",
      "        if print_loss and i%1000==0:\n",
      "            print \"Loss after iteration %i: %f\" %(i,calculate_loss(train_X,train_y))\n",
      "def accuracy_rate():\n",
      "    predict_result=predict(train_X)\n",
      "    count=0;\n",
      "    for i in range(len(predict_result)):\n",
      "        realResult=train_y[i]\n",
      "        if(realResult==predict_result[i]):\n",
      "            count+=1\n",
      "    print \"the correct rate is :%f\" %(float(count)/len(predict_result))\n",
      "\n",
      "def plot_decision_boundary(pred_func):\n",
      "    # Set min and max values and give it some padding\n",
      "    x_min, x_max = train_X[:, 0].min() - .5, train_X[:, 0].max() + .5\n",
      "    y_min, y_max = train_X[:, 1].min() - .5, train_X[:, 1].max() + .5\n",
      "    h = 0.01\n",
      "    # Generate a grid of points with distance h between them\n",
      "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
      "    # Predict the function value for the whole gid\n",
      "    Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
      "    Z = Z.reshape(xx.shape)\n",
      "    # Plot the contour and training examples\n",
      "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
      "    plt.scatter(train_X[:, 0], train_X[:, 1], c=train_y, cmap=plt.cm.Spectral)\n",
      "    plt.show()\n",
      "\n",
      "\n",
      "build_model(print_loss=True)\n",
      "accuracy_rate()\n",
      "# # plot_decision_boundary(lambda x: predict(x))\n",
      "# # plt.title(\"Decision Boundary for hidden layer size 3\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loss after iteration 0: 0.576888\n",
        "Loss after iteration 1000: 0.294892"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss after iteration 2000: 0.274580"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss after iteration 3000: 0.251601"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss after iteration 4000: 0.226158"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss after iteration 5000: 0.200661"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss after iteration 6000: 0.177555"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss after iteration 7000: 0.158112"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss after iteration 8000: 0.142428"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss after iteration 9000: 0.129994"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss after iteration 10000: 0.120157"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss after iteration 11000: 0.112324"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss after iteration 12000: 0.106024"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss after iteration 13000: 0.100896"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss after iteration 14000: 0.096674"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss after iteration 15000: 0.093158"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss after iteration 16000: 0.090197"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss after iteration 17000: 0.087680"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss after iteration 18000: 0.085520"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Loss after iteration 19000: 0.083651"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "the correct rate is :0.983333"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}