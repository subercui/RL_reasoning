{
 "metadata": {
  "name": "",
  "signature": "sha256:88480f0e664458b2e36b34c663c2d41c1298e6be4227d2d7d2a0df4e04eaa31d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.insert(0, \"./dataProcess\")\n",
      "from stream import preprocess\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "# from reasoning import Reason\n",
      "import logging\n",
      "\n",
      "import config\n",
      "import numpy\n",
      "from utils import *\n",
      "config = getattr(config, 'get_config')()\n",
      "train_files = config['train_file']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from theano.tensor.nnet import categorical_crossentropy\n",
      "class LogisticRegression(object):\n",
      "\n",
      "    def __init__(self, input, n_in, n_out):\n",
      "\n",
      "        # initialize with 0 the weights W as a matrix of shape (n_in, n_out)\n",
      "        self.W = param_init().uniform((n_in, n_out))\n",
      "        # initialize the baises b as a vector of n_out 0s\n",
      "        self.b = param_init().constant((n_out, ))\n",
      "\n",
      "        # compute vector of class-membership probabilities in symbolic form\n",
      "        energy = theano.dot(input, self.W) + self.b\n",
      "        if energy.ndim == 3:\n",
      "            energy_exp = T.exp(energy - T.max(energy, 2, keepdims=True))\n",
      "            pmf = energy_exp / energy_exp.sum(2, keepdims=True)\n",
      "        else:\n",
      "            pmf = T.nnet.softmax(energy)\n",
      "\n",
      "        self.p_y_given_x = pmf\n",
      "        self.y_pred = T.argmax(self.p_y_given_x, axis=-1)\n",
      "\n",
      "        # compute prediction as class whose probability is maximal in\n",
      "        # symbolic form\n",
      "\n",
      "        # parameters of the model\n",
      "        self.params = [self.W, self.b]\n",
      "\n",
      "    def cost(self, targets, mask=None):\n",
      "        prediction = self.p_y_given_x\n",
      "\n",
      "        if prediction.ndim == 3:\n",
      "        # prediction = prediction.dimshuffle(1,2,0).flatten(2).dimshuffle(1,0)\n",
      "            prediction_flat = prediction.reshape(((prediction.shape[0] *\n",
      "                                                prediction.shape[1]),\n",
      "                                                prediction.shape[2]), ndim=2)\n",
      "            targets_flat = targets.flatten()\n",
      "            mask_flat = mask.flatten()\n",
      "            ce = categorical_crossentropy(prediction_flat, targets_flat) * mask_flat\n",
      "        else:\n",
      "            ce = categorical_crossentropy(prediction, targets)\n",
      "        return T.sum(ce)\n",
      "\n",
      "    def errors(self, y):\n",
      "        y_pred = self.y_pred\n",
      "        if y.ndim == 2:\n",
      "            y = y.flatten()\n",
      "            y_pred = y_pred.flatten()\n",
      "        return T.sum(T.neq(y, y_pred))\n",
      "\n",
      "\n",
      "\n",
      "class GRU(object):\n",
      "\n",
      "    def __init__(self, n_in, n_hids, with_contex=False, **kwargs):\n",
      "        self.n_in = n_in\n",
      "        self.n_hids = n_hids\n",
      "        self.with_contex = with_contex\n",
      "        if self.with_contex:\n",
      "            self.c_hids = kwargs.pop('c_hids', n_hids)\n",
      "        self._init_params()\n",
      "\n",
      "    def _init_params(self):\n",
      "        n_in = self.n_in\n",
      "        n_hids = self.n_hids\n",
      "        size_xh = (n_in, n_hids)\n",
      "        size_hh = (n_hids, n_hids)\n",
      "        self.W_xz = param_init().uniform(size_xh)\n",
      "        self.W_xr = param_init().uniform(size_xh)\n",
      "        self.W_xh = param_init().uniform(size_xh)\n",
      "\n",
      "        self.W_hz = param_init().orth(size_hh)\n",
      "        self.W_hr = param_init().orth(size_hh)\n",
      "        self.W_hh = param_init().orth(size_hh)\n",
      "\n",
      "        self.b_z = param_init().constant((n_hids,))\n",
      "        self.b_r = param_init().constant((n_hids,))\n",
      "        self.b_h = param_init().constant((n_hids,))\n",
      "\n",
      "        self.params = [self.W_xz, self.W_xr, self.W_xh,\n",
      "                       self.W_hz, self.W_hr, self.W_hh,\n",
      "                       self.b_z, self.b_r, self.b_h]\n",
      "\n",
      "        if self.with_contex:\n",
      "            size_ch = (self.c_hids, self.n_hids)\n",
      "            self.W_cz = param_init().uniform(size_ch)\n",
      "            self.W_cr = param_init().uniform(size_ch)\n",
      "            self.W_ch = param_init().uniform(size_ch)\n",
      "            self.W_c_init = param_init().uniform(size_ch)\n",
      "\n",
      "            self.params = self.params + [self.W_cz, self.W_cr,\n",
      "                                         self.W_ch, self.W_c_init]\n",
      "\n",
      "    def _step_forward_with_context(self, x_t, x_m, h_tm1, c_z, c_r, c_h):\n",
      "        '''\n",
      "        x_t: input at time t\n",
      "        x_m: mask of x_t\n",
      "        h_tm1: previous state\n",
      "        c_x: contex of the rnn\n",
      "        '''\n",
      "        z_t = T.nnet.sigmoid(T.dot(x_t, self.W_xz) +\n",
      "                             T.dot(h_tm1, self.W_hz) + c_z + self.b_z)\n",
      "\n",
      "        r_t = T.nnet.sigmoid(T.dot(x_t, self.W_xr) +\n",
      "                             T.dot(h_tm1, self.W_hr) + c_r + self.b_r)\n",
      "\n",
      "        can_h_t = T.tanh(T.dot(x_t, self.W_xh) +\n",
      "                         r_t * T.dot(h_tm1, self.W_hh) + c_h +\n",
      "                         self.b_h)\n",
      "        h_t = (1 - z_t) * h_tm1 + z_t * can_h_t\n",
      "\n",
      "        h_t = x_m[:, None] * h_t + (1. - x_m[:, None])*h_tm1\n",
      "        return h_t\n",
      "\n",
      "\n",
      "    def _step_forward(self, x_t, x_m, h_tm1):\n",
      "        '''\n",
      "        x_t: input at time t\n",
      "        x_m: mask of x_t\n",
      "        h_tm1: previous state\n",
      "        c_x: contex of the rnn\n",
      "        '''\n",
      "        z_t = T.nnet.sigmoid(T.dot(x_t, self.W_xz) +\n",
      "                             T.dot(h_tm1, self.W_hz) + self.b_z)\n",
      "\n",
      "        r_t = T.nnet.sigmoid(T.dot(x_t, self.W_xr) +\n",
      "                             T.dot(h_tm1, self.W_hr) + self.b_r)\n",
      "\n",
      "        can_h_t = T.tanh(T.dot(x_t, self.W_xh) +\n",
      "                         r_t * T.dot(h_tm1, self.W_hh) +\n",
      "                         self.b_h)\n",
      "        h_t = (1 - z_t) * h_tm1 + z_t * can_h_t\n",
      "\n",
      "        h_t = x_m[:, None] * h_t + (1. - x_m[:, None])*h_tm1\n",
      "        return h_t\n",
      "\n",
      "    def apply(self, state_below, mask_below, init_state=None, context=None):\n",
      "        if state_below.ndim == 3:\n",
      "            batch_size = state_below.shape[1]\n",
      "            n_steps = state_below.shape[0]\n",
      "        else:\n",
      "            raise NotImplementedError\n",
      "\n",
      "\n",
      "        if self.with_contex:\n",
      "            if init_state is None:\n",
      "                init_state = T.tanh(theano.dot(context, self.W_c_init))\n",
      "            c_z = theano.dot(context, self.W_cz)\n",
      "            c_r = theano.dot(context, self.W_cr)\n",
      "            c_h = theano.dot(context, self.W_ch)\n",
      "            non_sequences = [c_z, c_r, c_h]\n",
      "            rval, updates = theano.scan(self._step_forward_with_context,\n",
      "                                        sequences=[state_below, mask_below],\n",
      "                                        outputs_info=[init_state],\n",
      "                                        non_sequences=non_sequences,\n",
      "                                        n_steps=n_steps\n",
      "                                        )\n",
      "\n",
      "        else:\n",
      "            if init_state is None:\n",
      "                init_state = T.alloc(numpy.float32(0.), batch_size, self.n_hids)\n",
      "            rval, updates = theano.scan(self._step_forward,\n",
      "                                        sequences=[state_below, mask_below],\n",
      "                                        outputs_info=[init_state],\n",
      "                                        n_steps=n_steps\n",
      "                                        )\n",
      "        self.output = rval\n",
      "        return self.output\n",
      "\n",
      "    def merge_out(self, state_below, mask_below, context=None):\n",
      "        hiddens = self.apply(state_below, mask_below, context=context)\n",
      "        if context is None:\n",
      "            msize = self.n_in + self.n_hids\n",
      "            osize = self.n_hids\n",
      "            combine = T.concatenate([state_below, hiddens], axis=2)\n",
      "        else:\n",
      "            msize = self.n_in + self.n_hids + self.c_hids\n",
      "            osize = self.n_hids\n",
      "            n_times = state_below.shape[0]\n",
      "            m_context = repeat_x(context, n_times)\n",
      "            combine = T.concatenate([state_below, hiddens, m_context], axis=2)\n",
      "\n",
      "        self.W_m = param_init().uniform((msize, osize*2))\n",
      "        self.b_m = param_init().constant((osize*2,))\n",
      "        self.params += [self.W_m, self.b_m]\n",
      "\n",
      "        merge_out = theano.dot(combine, self.W_m) + self.b_m\n",
      "        merge_max = merge_out.reshape((merge_out.shape[0],\n",
      "                                       merge_out.shape[1],\n",
      "                                       merge_out.shape[2]/2,\n",
      "                                       2), ndim=4).max(axis=3)\n",
      "        return merge_max * mask_below[:, :, None]\n",
      "\n",
      "\n",
      "class lookup_table(object):\n",
      "    def __init__(self, embsize, vocab_size):\n",
      "        self.W = param_init().uniform((vocab_size, embsize))\n",
      "        self.params = [self.W]\n",
      "        self.vocab_size = vocab_size\n",
      "        self.embsize = embsize\n",
      "\n",
      "    def apply(self, indices):\n",
      "        outshape = [indices.shape[i] for i\n",
      "                    in range(indices.ndim)] + [self.embsize]\n",
      "\n",
      "        return self.W[indices.flatten()].reshape(outshape)\n",
      "\n",
      "\n",
      "class auto_encoder(object):\n",
      "    def __init__(self, sentence, sentence_mask, vocab_size, n_in, n_hids, **kwargs):\n",
      "        layers = []\n",
      "\n",
      "        #batch_size = sentence.shape[1]\n",
      "        encoder = GRU(n_in, n_hids, with_contex=False)\n",
      "        layers.append(encoder)\n",
      "\n",
      "        if 'table' in kwargs:\n",
      "            table = kwargs['table']\n",
      "        else:\n",
      "            table = lookup_table(n_in, vocab_size)\n",
      "        # layers.append(table)\n",
      "\n",
      "        state_below = table.apply(sentence)\n",
      "        momeries = encoder.apply(state_below, sentence_mask) #(10,5,39)\n",
      "        context = momeries[-1] \n",
      "        \n",
      "        decoder = GRU(n_in, n_hids, with_contex=True)\n",
      "        layers.append(decoder)\n",
      "\n",
      "        decoder_state_below = table.apply(sentence[:-1])\n",
      "        hiddens = decoder.merge_out(decoder_state_below,\n",
      "                                    sentence_mask[:-1], context=context)\n",
      "\n",
      "        logistic_layer = LogisticRegression(hiddens, n_hids, vocab_size)\n",
      "        layers.append(logistic_layer)\n",
      "\n",
      "        self.cost = logistic_layer.cost(sentence[1:],\n",
      "                                        sentence_mask[1:])/sentence_mask[1:].sum() #predict model cost\n",
      "        self.output = momeries\n",
      "        self.params = []\n",
      "        for layer in layers:\n",
      "            self.params.extend(layer.params)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Memory(object):\n",
      "    \"\"\"\n",
      "    author:liuxianggen\n",
      "    \"\"\"\n",
      "    def __init__(self, **kwargs):\n",
      "        self.vocab_size = kwargs.pop('vocab_size')\n",
      "        self.n_in = kwargs.pop('nemb')\n",
      "        self.n_hids = kwargs.pop('nhids')\n",
      "        self.n_layer = kwargs.pop('n_layer')\n",
      "        self.n_label = kwargs.pop('label_size')\n",
      "        self.params=[]\n",
      "        self.cost = 0\n",
      "\n",
      "    def apply(self, facts, facts_mask, question, question_mask, y):\n",
      "        table = lookup_table(self.n_in, self.vocab_size)\n",
      "        self.params += table.params\n",
      "        facts_encoder = auto_encoder(facts, facts_mask, self.vocab_size,\n",
      "                                     self.n_in, self.n_hids, table=table)\n",
      "        self.params += facts_encoder.params\n",
      "        self.eval = facts_encoder.output #(10,5,39)\n",
      "        self.cost = facts_encoder.cost\n",
      "        return self.eval\n",
      "    \n",
      "    \n",
      "\n",
      "# \tdef append(self, entry):\n",
      "# \t\tself.entries.append(entry)\n",
      "\n",
      "# \tdef read(self, index):\n",
      "# \t\treturn self.entries[index]\n",
      " #####################\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utils import adadelta\n",
      "x = T.lmatrix()\n",
      "x_mask = T.matrix()\n",
      "y = T.lmatrix()\n",
      "y_mask = T.matrix()\n",
      "l = T.lvector()\n",
      "\n",
      "\n",
      "memory = Memory(**config)\n",
      "context = memory.apply(x, x_mask, y, y_mask, l) #(10,5,39)\n",
      "gcost = memory.cost\n",
      "# add regularization\n",
      "params = memory.params\n",
      "\n",
      "for param in params:\n",
      "    gcost += T.sum(param ** 2) * 1e-6  #l2\n",
      "    gcost += T.sum(abs(param)) * 1e-6  #l1\n",
      "grads = T.grad(gcost, params)\n",
      "updates = adadelta(params, grads)\n",
      "fn = theano.function([x, x_mask, y, y_mask, l], [memory.cost], updates=updates,on_unused_input='ignore')\n",
      "\n",
      "data_class = preprocess(*train_files)\n",
      "# test_class = preprocess(*test_files)\n",
      "for _ in range(100):\n",
      "    sums = 0.0\n",
      "    i = 0\n",
      "    for facts, question, label in data_class.data_stream():\n",
      "        sums += fn(facts[0].T, facts[1].T, question[0].T, question[1].T, label)[0]\n",
      "        i += label.shape[0]\n",
      "    print \"train error: {}\".format(float(sums/float(i)))\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train error: 0.579258748323\n",
        "train error: 0.554563991147"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train error: 0.554213794053"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train error: 0.554130090094"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train error: 0.554094441789"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train error: 0.554077223533"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train error: 0.554065329581"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train error: 0.554065439302"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train error: 0.55407359612"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"train error: {}\".format(3231)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train error: 3231\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "config = getattr(config, 'get_config')()test_files = config['test_file']\n",
      "print train_files # ['../data/19.train.fact', '../data/19.train.ques', '../data/19.train.answer']\n",
      "print test_files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['/home/agen/workspace-python/RL_reasoning/data/19.train.fact', '/home/agen/workspace-python/RL_reasoning/data/19.train.ques', '/home/agen/workspace-python/RL_reasoning/data/19.train.answer']\n",
        "['/home/agen/workspace-python/RL_reasoning/data/19.test.fact', '/home/agen/workspace-python/RL_reasoning/data/19.test.ques', '/home/agen/workspace-python/RL_reasoning/data/19.test.answer']\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 9 21  0  2 14 20 21 16 11  5]\n",
        " [ 9 21 19  2 17 20 21  0 11  5]\n",
        " [ 9 21 18  2 10 20 21  3 11  5]\n",
        " [ 9 21  0  2 10 20 21 18 11  5]\n",
        " [ 9 21  6  2 17 20 21 18 11  5]]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}